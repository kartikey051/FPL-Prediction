{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (4.39.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (4.14.3)\n",
      "Requirement already satisfied: pandas in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: webdriver-manager in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.6.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from selenium) (2025.11.12)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.2)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: requests in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from webdriver-manager) (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from webdriver-manager) (1.2.1)\n",
      "Requirement already satisfied: packaging in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/tarun/Documents/Python_Practice/venv/lib/python3.14/site-packages (from requests->webdriver-manager) (3.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium beautifulsoup4 pandas webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting automatic WebDriver setup...\n",
      "‚úÖ Automatic WebDriver setup successful.\n",
      "\n",
      "============================================================\n",
      "STEP 1: Extracting Player Links\n",
      "============================================================\n",
      "Fetching player list from wages page (Attempt 1)...\n",
      "  Page load timeout, but attempting to parse anyway...\n",
      "  üìù Saved page HTML to debug_wages_page.html for inspection\n",
      "  Found 2709 total links on page\n",
      "    Found: Cristiano Ronaldo\n",
      "    Found: Lionel Messi\n",
      "    Found: Rayan Cherki\n",
      "    Found: Manu Kon√©\n",
      "    Found: Erling Haaland\n",
      "  Total unique players found: 633\n",
      "‚úÖ Successfully extracted 633 players\n",
      "\n",
      "Total players to scrape: 633\n",
      "\n",
      "============================================================\n",
      "STEP 2: Scraping Player Match Logs\n",
      "============================================================\n",
      "\n",
      "\n",
      "[1/633] Processing: Cristiano Ronaldo\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/dea698d9/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Cristiano Ronaldo\n",
      "  üíæ Saved individual file: Cristiano_Ronaldo_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 0.95 seconds...\n",
      "\n",
      "[2/633] Processing: Lionel Messi\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/d70ce98e/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n",
      "  ‚ö†Ô∏è  No data extracted for Lionel Messi\n",
      "  ‚è±Ô∏è  Sleeping for 1.41 seconds...\n",
      "\n",
      "[3/633] Processing: Rayan Cherki\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/b34c63a5/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n",
      "  Timeout (Attempt 1). Retrying...\n",
      "  Scraping match logs (Attempt 2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Rayan Cherki\n",
      "  üíæ Saved individual file: Rayan_Cherki_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.17 seconds...\n",
      "\n",
      "[4/633] Processing: Manu Kon√©\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/86574238/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Manu Kon√©\n",
      "  üíæ Saved individual file: Manu_Kon√©_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.12 seconds...\n",
      "\n",
      "[5/633] Processing: Erling Haaland\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/1f44ac21/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Erling Haaland\n",
      "  üíæ Saved individual file: Erling_Haaland_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.33 seconds...\n",
      "\n",
      "[6/633] Processing: James Garner\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/4e015693/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for James Garner\n",
      "  üíæ Saved individual file: James_Garner_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.54 seconds...\n",
      "\n",
      "[7/633] Processing: Florian Wirtz\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/e7fcf289/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Florian Wirtz\n",
      "  üíæ Saved individual file: Florian_Wirtz_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.45 seconds...\n",
      "\n",
      "[8/633] Processing: Bukayo Saka\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/bc7dc64d/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Bukayo Saka\n",
      "  üíæ Saved individual file: Bukayo_Saka_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.82 seconds...\n",
      "\n",
      "[9/633] Processing: Elliot Anderson\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/de31038e/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Elliot Anderson\n",
      "  üíæ Saved individual file: Elliot_Anderson_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.44 seconds...\n",
      "\n",
      "[10/633] Processing: Yan Diomand√©\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/919f5f54/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Yan Diomand√©\n",
      "  üíæ Saved individual file: Yan_Diomand√©_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.11 seconds...\n",
      "\n",
      "[11/633] Processing: Noni Madueke\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/bf34eebd/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Noni Madueke\n",
      "  üíæ Saved individual file: Noni_Madueke_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.58 seconds...\n",
      "\n",
      "[12/633] Processing: Viktor Gy√∂keres\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/4d5a9185/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Viktor Gy√∂keres\n",
      "  üíæ Saved individual file: Viktor_Gy√∂keres_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.39 seconds...\n",
      "\n",
      "[13/633] Processing: Chloe Kelly\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/9ff67bf9/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Chloe Kelly\n",
      "  üíæ Saved individual file: Chloe_Kelly_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.77 seconds...\n",
      "\n",
      "[14/633] Processing: Bruno Fernandes\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/507c7bdf/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Bruno Fernandes\n",
      "  üíæ Saved individual file: Bruno_Fernandes_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.15 seconds...\n",
      "\n",
      "[15/633] Processing: Beth Mead\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/921c8f1d/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Beth Mead\n",
      "  üíæ Saved individual file: Beth_Mead_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.49 seconds...\n",
      "\n",
      "[16/633] Processing: Marta\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/3857e361/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n",
      "  ‚ö†Ô∏è  No data extracted for Marta\n",
      "  ‚è±Ô∏è  Sleeping for 1.96 seconds...\n",
      "\n",
      "[17/633] Processing: Xavi Simons\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/da4d670f/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Xavi Simons\n",
      "  üíæ Saved individual file: Xavi_Simons_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.11 seconds...\n",
      "\n",
      "[18/633] Processing: Antoine Semenyo\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/efd2ec23/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Antoine Semenyo\n",
      "  üíæ Saved individual file: Antoine_Semenyo_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.79 seconds...\n",
      "\n",
      "[19/633] Processing: Vinicius J√∫nior\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/7111d552/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Vinicius J√∫nior\n",
      "  üíæ Saved individual file: Vinicius_J√∫nior_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 0.99 seconds...\n",
      "\n",
      "[20/633] Processing: Christian Pulisic\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/1bf33a9a/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Christian Pulisic\n",
      "  üíæ Saved individual file: Christian_Pulisic_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.73 seconds...\n",
      "\n",
      "[21/633] Processing: Manuel Locatelli\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/a8a874f1/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Manuel Locatelli\n",
      "  üíæ Saved individual file: Manuel_Locatelli_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 0.82 seconds...\n",
      "\n",
      "[22/633] Processing: Alexis Mac Allister\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/83d074ff/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Alexis Mac Allister\n",
      "  üíæ Saved individual file: Alexis_Mac_Allister_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.20 seconds...\n",
      "\n",
      "[23/633] Processing: Yui Hasegawa\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/13633403/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Yui Hasegawa\n",
      "  üíæ Saved individual file: Yui_Hasegawa_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.48 seconds...\n",
      "\n",
      "[24/633] Processing: Jordan Henderson\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/935e6b8f/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Jordan Henderson\n",
      "  üíæ Saved individual file: Jordan_Henderson_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.36 seconds...\n",
      "\n",
      "[25/633] Processing: Hitomi Tanaka\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/e07cbd99/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Hitomi Tanaka\n",
      "  üíæ Saved individual file: Hitomi_Tanaka_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.35 seconds...\n",
      "\n",
      "[26/633] Processing: Aitana Bonmat√≠\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/f3d165f5/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Aitana Bonmat√≠\n",
      "  üíæ Saved individual file: Aitana_Bonmat√≠_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.10 seconds...\n",
      "\n",
      "[27/633] Processing: Ayyoub Bouaddi\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/8006228f/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Ayyoub Bouaddi\n",
      "  üíæ Saved individual file: Ayyoub_Bouaddi_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.78 seconds...\n",
      "\n",
      "[28/633] Processing: √âderson\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/a9202def/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for √âderson\n",
      "  üíæ Saved individual file: √âderson_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.20 seconds...\n",
      "\n",
      "[29/633] Processing: Enzo Barrenechea\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/6caffe81/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Enzo Barrenechea\n",
      "  üíæ Saved individual file: Enzo_Barrenechea_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.59 seconds...\n",
      "\n",
      "[30/633] Processing: Jo√£o Gomes\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/8b57ad2c/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Jo√£o Gomes\n",
      "  üíæ Saved individual file: Jo√£o_Gomes_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.06 seconds...\n",
      "\n",
      "[31/633] Processing: Matheus Nunes\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/e6af02e0/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Matheus Nunes\n",
      "  üíæ Saved individual file: Matheus_Nunes_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.36 seconds...\n",
      "\n",
      "[32/633] Processing: Rodri\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/6434f10d/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Rodri\n",
      "  üíæ Saved individual file: Rodri_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.09 seconds...\n",
      "\n",
      "[33/633] Processing: Murillo\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/1704b0b8/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Murillo\n",
      "  üíæ Saved individual file: Murillo_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.23 seconds...\n",
      "\n",
      "[34/633] Processing: Myles Lewis-Skelly\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/5dff6c28/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Myles Lewis-Skelly\n",
      "  üíæ Saved individual file: Myles_Lewis-Skelly_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.14 seconds...\n",
      "\n",
      "[35/633] Processing: Lucy Bronze\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/5056c581/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Lucy Bronze\n",
      "  üíæ Saved individual file: Lucy_Bronze_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.82 seconds...\n",
      "\n",
      "[36/633] Processing: Virgil van Dijk\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/e06683ca/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Virgil van Dijk\n",
      "  üíæ Saved individual file: Virgil_van_Dijk_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.74 seconds...\n",
      "\n",
      "[37/633] Processing: Ellyse Perry\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/09e6fe46/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n",
      "  ‚ö†Ô∏è  No data extracted for Ellyse Perry\n",
      "  ‚è±Ô∏è  Sleeping for 1.38 seconds...\n",
      "\n",
      "[38/633] Processing: Malick Fofana\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/8236f673/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Malick Fofana\n",
      "  üíæ Saved individual file: Malick_Fofana_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.05 seconds...\n",
      "\n",
      "[39/633] Processing: Nico Schlotterbeck\n",
      "--------------------------------------------------\n",
      "  Match log URL: https://fbref.com/en/players/34e12499/matchlogs/all_comps/\n",
      "  Scraping match logs (Attempt 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/rfr14j2j62n1zftp1z06v_bm0000gn/T/ipykernel_4269/3753183786.py:277: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Scraped 5 match logs for Nico Schlotterbeck\n",
      "  üíæ Saved individual file: Nico_Schlotterbeck_match_logs.csv\n",
      "  ‚è±Ô∏è  Sleeping for 1.03 seconds...\n",
      "\n",
      "[40/633] Processing: Sarah Gorden\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Sarah Gorden\n",
      "\n",
      "[41/633] Processing: Arijanet Muric\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Arijanet Muric\n",
      "\n",
      "[42/633] Processing: Jason Steele\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jason Steele\n",
      "\n",
      "[43/633] Processing: Ann-Katrin Berger\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ann-Katrin Berger\n",
      "\n",
      "[44/633] Processing: Bernd Leno\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Bernd Leno\n",
      "\n",
      "[45/633] Processing: Hannah Hampton\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Hannah Hampton\n",
      "\n",
      "[46/633] Processing: Elia Caprile\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Elia Caprile\n",
      "\n",
      "[47/633] Processing: James Wright\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for James Wright\n",
      "\n",
      "[48/633] Processing: Nick Pope\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nick Pope\n",
      "\n",
      "[49/633] Processing: Senne Lammens\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Senne Lammens\n",
      "\n",
      "[50/633] Processing: Player Index By Nationality\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Player Index By Nationality\n",
      "\n",
      "[51/633] Processing: David Raya\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for David Raya\n",
      "\n",
      "[52/633] Processing: Mohamed Salah\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mohamed Salah\n",
      "\n",
      "[53/633] Processing: Casemiro\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Casemiro\n",
      "\n",
      "[54/633] Processing: Raheem Sterling\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Raheem Sterling\n",
      "\n",
      "[55/633] Processing: Bernardo Silva\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Bernardo Silva\n",
      "\n",
      "[56/633] Processing: Omar Marmoush\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Omar Marmoush\n",
      "\n",
      "[57/633] Processing: Kai Havertz\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kai Havertz\n",
      "\n",
      "[58/633] Processing: Alexander Isak\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Alexander Isak\n",
      "\n",
      "[59/633] Processing: Gabriel Jesus\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Gabriel Jesus\n",
      "\n",
      "[60/633] Processing: William Saliba\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for William Saliba\n",
      "\n",
      "[61/633] Processing: Cody Gakpo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Cody Gakpo\n",
      "\n",
      "[62/633] Processing: Gianluigi Donnarumma\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Gianluigi Donnarumma\n",
      "\n",
      "[63/633] Processing: John Stones\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for John Stones\n",
      "\n",
      "[64/633] Processing: R√∫ben Dias\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for R√∫ben Dias\n",
      "\n",
      "[65/633] Processing: Reece James\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Reece James\n",
      "\n",
      "[66/633] Processing: Declan Rice\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Declan Rice\n",
      "\n",
      "[67/633] Processing: Martin √òdegaard\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Martin √òdegaard\n",
      "\n",
      "[68/633] Processing: Tijjani Reijnders\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tijjani Reijnders\n",
      "\n",
      "[69/633] Processing: Phil Foden\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Phil Foden\n",
      "\n",
      "[70/633] Processing: Hugo Ekitike\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Hugo Ekitike\n",
      "\n",
      "[71/633] Processing: Jo≈°ko Gvardiol\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jo≈°ko Gvardiol\n",
      "\n",
      "[72/633] Processing: Wesley Fofana\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Wesley Fofana\n",
      "\n",
      "[73/633] Processing: Matthijs de Ligt\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Matthijs de Ligt\n",
      "\n",
      "[74/633] Processing: Cristian Romero\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Cristian Romero\n",
      "\n",
      "[75/633] Processing: Harry Maguire\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Harry Maguire\n",
      "\n",
      "[76/633] Processing: Eberechi Eze\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Eberechi Eze\n",
      "\n",
      "[77/633] Processing: Gabriel Martinelli\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Gabriel Martinelli\n",
      "\n",
      "[78/633] Processing: Leandro Trossard\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Leandro Trossard\n",
      "\n",
      "[79/633] Processing: Matheus Cunha\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Matheus Cunha\n",
      "\n",
      "[80/633] Processing: Enzo Fern√°ndez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Enzo Fern√°ndez\n",
      "\n",
      "[81/633] Processing: Marc Cucurella\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Marc Cucurella\n",
      "\n",
      "[82/633] Processing: James Maddison\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for James Maddison\n",
      "\n",
      "[83/633] Processing: Benjamin ≈†e≈°ko\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Benjamin ≈†e≈°ko\n",
      "\n",
      "[84/633] Processing: Andrew Robertson\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Andrew Robertson\n",
      "\n",
      "[85/633] Processing: Bruno Guimar√£es\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Bruno Guimar√£es\n",
      "\n",
      "[86/633] Processing: Nathan Ak√©\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nathan Ak√©\n",
      "\n",
      "[87/633] Processing: Pedro Neto\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Pedro Neto\n",
      "\n",
      "[88/633] Processing: Ben White\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ben White\n",
      "\n",
      "[89/633] Processing: Gabriel Magalh√£es\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Gabriel Magalh√£es\n",
      "\n",
      "[90/633] Processing: Bryan Mbeumo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Bryan Mbeumo\n",
      "\n",
      "[91/633] Processing: Luke Shaw\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Luke Shaw\n",
      "\n",
      "[92/633] Processing: Mason Mount\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mason Mount\n",
      "\n",
      "[93/633] Processing: Mohammed Kudus\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mohammed Kudus\n",
      "\n",
      "[94/633] Processing: Randal Kolo Muani\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Randal Kolo Muani\n",
      "\n",
      "[95/633] Processing: Jarrod Bowen\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jarrod Bowen\n",
      "\n",
      "[96/633] Processing: Lucas Paquet√°\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Lucas Paquet√°\n",
      "\n",
      "[97/633] Processing: Alisson\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Alisson\n",
      "\n",
      "[98/633] Processing: Federico Chiesa\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Federico Chiesa\n",
      "\n",
      "[99/633] Processing: Ryan Gravenberch\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ryan Gravenberch\n",
      "\n",
      "[100/633] Processing: Boubacar Kamara\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Boubacar Kamara\n",
      "\n",
      "[101/633] Processing: Emiliano Mart√≠nez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Emiliano Mart√≠nez\n",
      "\n",
      "[102/633] Processing: Morgan Rogers\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Morgan Rogers\n",
      "\n",
      "[103/633] Processing: Youri Tielemans\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Youri Tielemans\n",
      "\n",
      "[104/633] Processing: Anthony Gordon\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Anthony Gordon\n",
      "\n",
      "[105/633] Processing: Joelinton\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Joelinton\n",
      "\n",
      "[106/633] Processing: Sandro Tonali\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Sandro Tonali\n",
      "\n",
      "[107/633] Processing: Kalvin Phillips\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kalvin Phillips\n",
      "\n",
      "[108/633] Processing: Mateo Kovaƒçiƒá\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mateo Kovaƒçiƒá\n",
      "\n",
      "[109/633] Processing: Mois√©s Caicedo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mois√©s Caicedo\n",
      "\n",
      "[110/633] Processing: Jordan Pickford\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jordan Pickford\n",
      "\n",
      "[111/633] Processing: Dominic Solanke\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dominic Solanke\n",
      "\n",
      "[112/633] Processing: Amadou Onana\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Amadou Onana\n",
      "\n",
      "[113/633] Processing: Donyell Malen\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Donyell Malen\n",
      "\n",
      "[114/633] Processing: Yoane Wissa\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Yoane Wissa\n",
      "\n",
      "[115/633] Processing: Noussair Mazraoui\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Noussair Mazraoui\n",
      "\n",
      "[116/633] Processing: Jo√£o Palhinha\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jo√£o Palhinha\n",
      "\n",
      "[117/633] Processing: Lucas Digne\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Lucas Digne\n",
      "\n",
      "[118/633] Processing: Douglas Luiz\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Douglas Luiz\n",
      "\n",
      "[119/633] Processing: Nick Woltemade\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nick Woltemade\n",
      "\n",
      "[120/633] Processing: Mikel Merino\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mikel Merino\n",
      "\n",
      "[121/633] Processing: John McGinn\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for John McGinn\n",
      "\n",
      "[122/633] Processing: Ollie Watkins\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ollie Watkins\n",
      "\n",
      "[123/633] Processing: Cole Palmer\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Cole Palmer\n",
      "\n",
      "[124/633] Processing: Jo√£o Pedro\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jo√£o Pedro\n",
      "\n",
      "[125/633] Processing: Riccardo Calafiori\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Riccardo Calafiori\n",
      "\n",
      "[126/633] Processing: Amad Diallo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Amad Diallo\n",
      "\n",
      "[127/633] Processing: Lisandro Mart√≠nez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Lisandro Mart√≠nez\n",
      "\n",
      "[128/633] Processing: Manuel Ugarte\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Manuel Ugarte\n",
      "\n",
      "[129/633] Processing: Alphonse Areola\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Alphonse Areola\n",
      "\n",
      "[130/633] Processing: Dominik Szoboszlai\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dominik Szoboszlai\n",
      "\n",
      "[131/633] Processing: Victor Lindel√∂f\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Victor Lindel√∂f\n",
      "\n",
      "[132/633] Processing: Aaron Ramsdale\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Aaron Ramsdale\n",
      "\n",
      "[133/633] Processing: Jacob Ramsey\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jacob Ramsey\n",
      "\n",
      "[134/633] Processing: Kieran Trippier\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kieran Trippier\n",
      "\n",
      "[135/633] Processing: Rayan A√Øt-Nouri\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Rayan A√Øt-Nouri\n",
      "\n",
      "[136/633] Processing: Jorrel Hato\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jorrel Hato\n",
      "\n",
      "[137/633] Processing: Tosin Adarabioyo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tosin Adarabioyo\n",
      "\n",
      "[138/633] Processing: Idrissa Gana Gueye\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Idrissa Gana Gueye\n",
      "\n",
      "[139/633] Processing: James Tarkowski\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for James Tarkowski\n",
      "\n",
      "[140/633] Processing: Jarrad Branthwaite\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jarrad Branthwaite\n",
      "\n",
      "[141/633] Processing: Samuel Chukwueze\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Samuel Chukwueze\n",
      "\n",
      "[142/633] Processing: Leny Yoro\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Leny Yoro\n",
      "\n",
      "[143/633] Processing: James Ward-Prowse\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for James Ward-Prowse\n",
      "\n",
      "[144/633] Processing: Dejan Kulusevski\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dejan Kulusevski\n",
      "\n",
      "[145/633] Processing: Tyrone Mings\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tyrone Mings\n",
      "\n",
      "[146/633] Processing: Granit Xhaka\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Granit Xhaka\n",
      "\n",
      "[147/633] Processing: Alejandro Garnacho\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Alejandro Garnacho\n",
      "\n",
      "[148/633] Processing: Morgan Gibbs-White\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Morgan Gibbs-White\n",
      "\n",
      "[149/633] Processing: Jamie Gittens\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jamie Gittens\n",
      "\n",
      "[150/633] Processing: Joshua Zirkzee\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Joshua Zirkzee\n",
      "\n",
      "[151/633] Processing: Daichi Kamada\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Daichi Kamada\n",
      "\n",
      "[152/633] Processing: Nikola Milenkoviƒá\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nikola Milenkoviƒá\n",
      "\n",
      "[153/633] Processing: Brennan Johnson\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Brennan Johnson\n",
      "\n",
      "[154/633] Processing: Dean Henderson\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dean Henderson\n",
      "\n",
      "[155/633] Processing: Dominic Calvert-Lewin\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dominic Calvert-Lewin\n",
      "\n",
      "[156/633] Processing: Max Kilman\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Max Kilman\n",
      "\n",
      "[157/633] Processing: Jeremie Frimpong\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jeremie Frimpong\n",
      "\n",
      "[158/633] Processing: Ian Maatsen\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ian Maatsen\n",
      "\n",
      "[159/633] Processing: Matty Cash\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Matty Cash\n",
      "\n",
      "[160/633] Processing: Pau Torres\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Pau Torres\n",
      "\n",
      "[161/633] Processing: Nordi Mukiele\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nordi Mukiele\n",
      "\n",
      "[162/633] Processing: Anthony Elanga\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Anthony Elanga\n",
      "\n",
      "[163/633] Processing: Levi Colwill\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Levi Colwill\n",
      "\n",
      "[164/633] Processing: Liam Delap\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Liam Delap\n",
      "\n",
      "[165/633] Processing: Mykhailo Mudryk\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mykhailo Mudryk\n",
      "\n",
      "[166/633] Processing: Ra√∫l Jim√©nez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ra√∫l Jim√©nez\n",
      "\n",
      "[167/633] Processing: J√∏rgen Strand Larsen\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for J√∏rgen Strand Larsen\n",
      "\n",
      "[168/633] Processing: Jurri√´n Timber\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jurri√´n Timber\n",
      "\n",
      "[169/633] Processing: Micky van de Ven\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Micky van de Ven\n",
      "\n",
      "[170/633] Processing: Richarlison\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Richarlison\n",
      "\n",
      "[171/633] Processing: Eddie Nketiah\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Eddie Nketiah\n",
      "\n",
      "[172/633] Processing: Jack Harrison\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jack Harrison\n",
      "\n",
      "[173/633] Processing: Aaron Wan-Bissaka\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Aaron Wan-Bissaka\n",
      "\n",
      "[174/633] Processing: Niclas F√ºllkrug\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Niclas F√ºllkrug\n",
      "\n",
      "[175/633] Processing: Tom√°≈° Souƒçek\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tom√°≈° Souƒçek\n",
      "\n",
      "[176/633] Processing: Sven Botman\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Sven Botman\n",
      "\n",
      "[177/633] Processing: Stefan Ortega\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Stefan Ortega\n",
      "\n",
      "[178/633] Processing: Beno√Æt Badiashile\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Beno√Æt Badiashile\n",
      "\n",
      "[179/633] Processing: Kiernan Dewsbury-Hall\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kiernan Dewsbury-Hall\n",
      "\n",
      "[180/633] Processing: Callum Hudson-Odoi\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Callum Hudson-Odoi\n",
      "\n",
      "[181/633] Processing: Chris Wood\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Chris Wood\n",
      "\n",
      "[182/633] Processing: Joachim Andersen\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Joachim Andersen\n",
      "\n",
      "[183/633] Processing: Ferdi Kadioglu\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ferdi Kadioglu\n",
      "\n",
      "[184/633] Processing: Diogo Dalot\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Diogo Dalot\n",
      "\n",
      "[185/633] Processing: Pedro Porro\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Pedro Porro\n",
      "\n",
      "[186/633] Processing: Radu DrƒÉgu»ôin\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Radu DrƒÉgu»ôin\n",
      "\n",
      "[187/633] Processing: Evanilson\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Evanilson\n",
      "\n",
      "[188/633] Processing: Giorgi Mamardashvili\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Giorgi Mamardashvili\n",
      "\n",
      "[189/633] Processing: Joe Gomez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Joe Gomez\n",
      "\n",
      "[190/633] Processing: Emmanuel Agbadou\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Emmanuel Agbadou\n",
      "\n",
      "[191/633] Processing: Lutsharel Geertruida\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Lutsharel Geertruida\n",
      "\n",
      "[192/633] Processing: Dan Ndoye\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Dan Ndoye\n",
      "\n",
      "[193/633] Processing: Ethan Nwaneri\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ethan Nwaneri\n",
      "\n",
      "[194/633] Processing: Ben Davies\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ben Davies\n",
      "\n",
      "[195/633] Processing: Justin Kluivert\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Justin Kluivert\n",
      "\n",
      "[196/633] Processing: Sean Longstaff\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Sean Longstaff\n",
      "\n",
      "[197/633] Processing: Jean-Clair Todibo\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jean-Clair Todibo\n",
      "\n",
      "[198/633] Processing: Toti Gomes\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Toti Gomes\n",
      "\n",
      "[199/633] Processing: Harvey Barnes\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Harvey Barnes\n",
      "\n",
      "[200/633] Processing: Joe Willock\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Joe Willock\n",
      "\n",
      "[201/633] Processing: S√°vio\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for S√°vio\n",
      "\n",
      "[202/633] Processing: Axel Disasi\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Axel Disasi\n",
      "\n",
      "[203/633] Processing: Kaoru Mitoma\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kaoru Mitoma\n",
      "\n",
      "[204/633] Processing: Lewis Dunk\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Lewis Dunk\n",
      "\n",
      "[205/633] Processing: Michael Keane\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Michael Keane\n",
      "\n",
      "[206/633] Processing: Alex Iwobi\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Alex Iwobi\n",
      "\n",
      "[207/633] Processing: Mart√≠n Zubimendi\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mart√≠n Zubimendi\n",
      "\n",
      "[208/633] Processing: Tyrell Malacia\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tyrell Malacia\n",
      "\n",
      "[209/633] Processing: Archie Gray\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Archie Gray\n",
      "\n",
      "[210/633] Processing: Destiny Udogie\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Destiny Udogie\n",
      "\n",
      "[211/633] Processing: Guglielmo Vicario\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Guglielmo Vicario\n",
      "\n",
      "[212/633] Processing: Rodrigo Bentancur\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Rodrigo Bentancur\n",
      "\n",
      "[213/633] Processing: Daniel James\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Daniel James\n",
      "\n",
      "[214/633] Processing: Guido Rodr√≠guez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Guido Rodr√≠guez\n",
      "\n",
      "[215/633] Processing: Conor Bradley\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Conor Bradley\n",
      "\n",
      "[216/633] Processing: Milos Kerkez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Milos Kerkez\n",
      "\n",
      "[217/633] Processing: Emi Buend√≠a\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Emi Buend√≠a\n",
      "\n",
      "[218/633] Processing: Evann Guessand\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Evann Guessand\n",
      "\n",
      "[219/633] Processing: Ezri Konsa\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ezri Konsa\n",
      "\n",
      "[220/633] Processing: Jean-Ricner Bellegarde\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jean-Ricner Bellegarde\n",
      "\n",
      "[221/633] Processing: Tolu Arokodare\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Tolu Arokodare\n",
      "\n",
      "[222/633] Processing: Enzo Le F√©e\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Enzo Le F√©e\n",
      "\n",
      "[223/633] Processing: Kyle Walker\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Kyle Walker\n",
      "\n",
      "[224/633] Processing: Malick Thiaw\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Malick Thiaw\n",
      "\n",
      "[225/633] Processing: Jack Grealish\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Jack Grealish\n",
      "\n",
      "[226/633] Processing: Nicol√°s Gonz√°lez\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Nicol√°s Gonz√°lez\n",
      "\n",
      "[227/633] Processing: Mikkel Damsgaard\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Mikkel Damsgaard\n",
      "\n",
      "[228/633] Processing: Georginio Rutter\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Georginio Rutter\n",
      "\n",
      "[229/633] Processing: Ibrahim Sangar√©\n",
      "--------------------------------------------------\n",
      "  ‚ö†Ô∏è  Could not find match log URL for Ibrahim Sangar√©\n",
      "\n",
      "[230/633] Processing: Noah Okafor\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, SessionNotCreatedException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom exception for interrupt handling\n",
    "class SigTermException(Exception):\n",
    "    \"\"\"Custom exception to signal the script was interrupted.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Attempt to import webdriver-manager for automatic driver handling\n",
    "try:\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    AUTOMATIC_DRIVER = True\n",
    "except ImportError:\n",
    "    AUTOMATIC_DRIVER = False\n",
    "    print(\"Warning: 'webdriver-manager' not installed. Using manual path only.\")\n",
    "\n",
    "# --- Configuration and Setup ---\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='player_scraper_errors.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define script parameters\n",
    "WAGES_URL = \"https://fbref.com/en/comps/9/wages/Premier-League-Wages\"\n",
    "OUTPUT_DIR = \"fbref_player_match_logs\"\n",
    "MANUAL_DRIVER_PATH = r\"C:\\Users\\vanim\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "START_DATE = datetime(2016, 1, 1)  # January 2016\n",
    "\n",
    "# Create base output directory\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# --- WebDriver Initialization ---\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"Initialize Chrome WebDriver with optimal settings.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    driver = None\n",
    "    try:\n",
    "        if AUTOMATIC_DRIVER:\n",
    "            print(\"Attempting automatic WebDriver setup...\")\n",
    "            service = Service(ChromeDriverManager().install())\n",
    "            driver = webdriver.Chrome(service=service, options=options)\n",
    "            print(\"‚úÖ Automatic WebDriver setup successful.\")\n",
    "        else:\n",
    "            raise ImportError(\"webdriver-manager not available.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Automatic setup failed or skipped. Trying manual setup as failsafe.\")\n",
    "        logging.warning(f\"Automatic WebDriver setup failed/skipped: {e}\")\n",
    "\n",
    "        try:\n",
    "            ser = Service(MANUAL_DRIVER_PATH)\n",
    "            driver = webdriver.Chrome(service=ser, options=options)\n",
    "            print(\"‚úÖ Manual WebDriver setup successful.\")\n",
    "\n",
    "        except SessionNotCreatedException as manual_e:\n",
    "            print(f\"‚ùå FATAL ERROR: Manual setup failed. Check if ChromeDriver version matches Chrome browser.\")\n",
    "            logging.critical(f\"FATAL WebDriver Error (Manual): {manual_e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        except WebDriverException as manual_e:\n",
    "            print(f\"‚ùå FATAL ERROR: Manual setup failed. Check the file path: {MANUAL_DRIVER_PATH}\")\n",
    "            logging.critical(f\"FATAL WebDriver Error (Manual): {manual_e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    if driver is None:\n",
    "        print(\"‚ùå FATAL ERROR: Driver could not be initialized. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Set timeouts\n",
    "    driver.set_page_load_timeout(60)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "driver = initialize_driver()\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def extract_player_links(driver, url, max_retries=3):\n",
    "    \"\"\"\n",
    "    Extracts all player profile links from the Premier League wages page.\n",
    "    Returns a list of dictionaries with player name and URL.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Fetching player list from wages page (Attempt {attempt + 1})...\")\n",
    "            \n",
    "            # Try to refresh the driver connection if having issues\n",
    "            if attempt > 0:\n",
    "                print(\"  Refreshing driver session...\")\n",
    "                try:\n",
    "                    driver.refresh()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for the wages table to load with a more specific condition\n",
    "            try:\n",
    "                WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(f\"  Page load timeout, but attempting to parse anyway...\")\n",
    "            \n",
    "            # Give the page a moment to fully render\n",
    "            time.sleep(3)\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # DEBUG: Save HTML to file for inspection\n",
    "            if attempt == 0:\n",
    "                with open(\"debug_wages_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(html)\n",
    "                print(\"  üìù Saved page HTML to debug_wages_page.html for inspection\")\n",
    "            \n",
    "            players = []\n",
    "            \n",
    "            # Strategy 1: Find ALL links that point to player profiles\n",
    "            all_links = soup.find_all(\"a\", href=True)\n",
    "            print(f\"  Found {len(all_links)} total links on page\")\n",
    "            \n",
    "            player_links_found = 0\n",
    "            for link in all_links:\n",
    "                href = link.get(\"href\", \"\")\n",
    "                # Player URLs follow pattern: /en/players/PLAYER_ID/PLAYER_NAME\n",
    "                if \"/players/\" in href and href.count(\"/\") >= 4:\n",
    "                    player_name = link.text.strip()\n",
    "                    \n",
    "                    # Skip if no name\n",
    "                    if not player_name or len(player_name) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    # Build full URL\n",
    "                    if not href.startswith(\"http\"):\n",
    "                        player_url = \"https://fbref.com\" + href\n",
    "                    else:\n",
    "                        player_url = href\n",
    "                    \n",
    "                    # Avoid duplicates\n",
    "                    if not any(p[\"name\"] == player_name for p in players):\n",
    "                        players.append({\n",
    "                            \"name\": player_name,\n",
    "                            \"url\": player_url\n",
    "                        })\n",
    "                        player_links_found += 1\n",
    "                        \n",
    "                        # Debug: Print first few players found\n",
    "                        if player_links_found <= 5:\n",
    "                            print(f\"    Found: {player_name}\")\n",
    "            \n",
    "            print(f\"  Total unique players found: {len(players)}\")\n",
    "            \n",
    "            if players:\n",
    "                print(f\"‚úÖ Successfully extracted {len(players)} players\")\n",
    "                return players\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è  No players extracted. Retrying...\")\n",
    "                \n",
    "                # DEBUG: Print sample of what we found\n",
    "                print(\"  Debug - Sample links found:\")\n",
    "                sample_links = [l.get(\"href\") for l in all_links[:10] if l.get(\"href\")]\n",
    "                for sl in sample_links:\n",
    "                    print(f\"    {sl}\")\n",
    "                \n",
    "                time.sleep(3)\n",
    "                continue\n",
    "            \n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout fetching player list (Attempt {attempt + 1})\")\n",
    "            print(f\"  Timeout (Attempt {attempt + 1}). Retrying...\")\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting player links (Attempt {attempt + 1}): {str(e)}\")\n",
    "            print(f\"  Error (Attempt {attempt + 1}): {str(e)}\")\n",
    "            import traceback\n",
    "            print(f\"  Traceback: {traceback.format_exc()}\")\n",
    "            time.sleep(3)\n",
    "    \n",
    "    print(f\"‚ùå Failed to extract player links after {max_retries} attempts.\")\n",
    "    print(f\"   Please check debug_wages_page.html to see the actual page content.\")\n",
    "    return []\n",
    "\n",
    "def get_match_log_url(driver, player_url, max_retries=3):\n",
    "    \"\"\"\n",
    "    Navigates to a player's profile and extracts the full match log URL.\n",
    "    Returns the match log URL or None if not found.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            driver.get(player_url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            time.sleep(2)\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # Look for \"Match Logs\" link\n",
    "            match_log_links = soup.find_all(\"a\", href=True)\n",
    "            for link in match_log_links:\n",
    "                if \"matchlogs\" in link[\"href\"] and \"all_comps\" in link[\"href\"]:\n",
    "                    full_url = \"https://fbref.com\" + link[\"href\"] if link[\"href\"].startswith(\"/\") else link[\"href\"]\n",
    "                    return full_url\n",
    "            \n",
    "            # Strategy 2: Construct URL from player ID\n",
    "            player_id = player_url.split(\"/players/\")[1].split(\"/\")[0] if \"/players/\" in player_url else None\n",
    "            \n",
    "            if player_id:\n",
    "                constructed_url = f\"https://fbref.com/en/players/{player_id}/matchlogs/all_comps/\"\n",
    "                return constructed_url\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout getting match log URL (Attempt {attempt + 1})\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting match log URL (Attempt {attempt + 1}): {str(e)}\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def scrape_match_logs(driver, match_log_url, player_name, max_retries=3):\n",
    "    \"\"\"\n",
    "    Scrapes all match logs for a player from their match log page.\n",
    "    Filters data from January 2016 onwards.\n",
    "    Returns a DataFrame with all match log data.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  Scraping match logs (Attempt {attempt + 1})...\")\n",
    "            driver.get(match_log_url)\n",
    "            \n",
    "            # Wait and give page time to load\n",
    "            time.sleep(2)\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # Find the match logs table - try multiple possible IDs\n",
    "            table = None\n",
    "            for table_id_pattern in [\"matchlogs_all\", \"matchlogs\", \"matchlogs_for\"]:\n",
    "                tables = soup.find_all(\"table\", {\"id\": lambda x: x and table_id_pattern in x})\n",
    "                if tables:\n",
    "                    table = tables[0]\n",
    "                    break\n",
    "            \n",
    "            if table is None:\n",
    "                logging.warning(f\"Match logs table not found for {player_name}\")\n",
    "                return None\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            try:\n",
    "                dfs = pd.read_html(str(table))\n",
    "                df = dfs[0] if dfs else None\n",
    "                \n",
    "                if df is None or df.empty:\n",
    "                    logging.warning(f\"Empty DataFrame for {player_name}\")\n",
    "                    return None\n",
    "                \n",
    "                # Handle multi-level column headers if present\n",
    "                if isinstance(df.columns, pd.MultiIndex):\n",
    "                    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "                \n",
    "                # Add player identification\n",
    "                df['Player_Name'] = player_name\n",
    "                df['Player_URL'] = match_log_url\n",
    "                \n",
    "                # Filter by date if Date column exists\n",
    "                date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "                if date_columns:\n",
    "                    date_col = date_columns[0]\n",
    "                    try:\n",
    "                        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                        df = df[df[date_col] >= START_DATE]\n",
    "                        df = df.dropna(subset=[date_col])\n",
    "                    except Exception as e:\n",
    "                        logging.warning(f\"Could not filter by date for {player_name}: {str(e)}\")\n",
    "                \n",
    "                print(f\"  ‚úÖ Scraped {len(df)} match logs for {player_name}\")\n",
    "                return df\n",
    "                \n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Error reading HTML table for {player_name}: {str(e)}\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Timeout scraping match logs for {player_name} (Attempt {attempt + 1})\")\n",
    "            print(f\"  Timeout (Attempt {attempt + 1}). Retrying...\")\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping match logs for {player_name} (Attempt {attempt + 1}): {str(e)}\")\n",
    "            print(f\"  Error (Attempt {attempt + 1}): {str(e)}. Retrying...\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"  ‚ùå Failed to scrape match logs for {player_name} after {max_retries} attempts\")\n",
    "    return None\n",
    "\n",
    "def consolidate_data(all_data_frames, output_dir):\n",
    "    \"\"\"Consolidates all collected DataFrames and saves them to a single CSV.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting data consolidation...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if all_data_frames:\n",
    "        consolidated_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "        consolidated_filename = os.path.join(output_dir, \"All_Player_Match_Logs_Consolidated.csv\")\n",
    "        consolidated_df.to_csv(consolidated_filename, index=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Consolidation successful!\")\n",
    "        print(f\"   Total match logs: {len(consolidated_df)}\")\n",
    "        print(f\"   Unique players: {consolidated_df['Player_Name'].nunique()}\")\n",
    "        print(f\"   Output file: {consolidated_filename}\")\n",
    "        print(\"\\nSample of consolidated data:\")\n",
    "        print(consolidated_df.head(10).to_string())\n",
    "        \n",
    "        return consolidated_df\n",
    "    else:\n",
    "        print(\"‚ùå No data was successfully scraped to consolidate.\")\n",
    "        return None\n",
    "\n",
    "# --- Main Execution Loop ---\n",
    "\n",
    "all_data_frames = []\n",
    "successful_players = 0\n",
    "failed_players = 0\n",
    "\n",
    "try:\n",
    "    # Step 1: Extract player links from wages page\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: Extracting Player Links\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    players = extract_player_links(driver, WAGES_URL)\n",
    "    \n",
    "    if not players:\n",
    "        print(\"‚ùå No players found. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(f\"\\nTotal players to scrape: {len(players)}\")\n",
    "    \n",
    "    # Step 2: Scrape match logs for each player\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: Scraping Player Match Logs\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for i, player in enumerate(players, 1):\n",
    "        print(f\"\\n[{i}/{len(players)}] Processing: {player['name']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Get match log URL\n",
    "            match_log_url = get_match_log_url(driver, player['url'])\n",
    "            \n",
    "            if not match_log_url:\n",
    "                print(f\"  ‚ö†Ô∏è  Could not find match log URL for {player['name']}\")\n",
    "                failed_players += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Match log URL: {match_log_url}\")\n",
    "            \n",
    "            # Scrape match logs\n",
    "            player_df = scrape_match_logs(driver, match_log_url, player['name'])\n",
    "            \n",
    "            if player_df is not None and not player_df.empty:\n",
    "                all_data_frames.append(player_df)\n",
    "                successful_players += 1\n",
    "                \n",
    "                # Save individual player file\n",
    "                safe_name = player['name'].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "                individual_file = os.path.join(OUTPUT_DIR, f\"{safe_name}_match_logs.csv\")\n",
    "                player_df.to_csv(individual_file, index=False)\n",
    "                print(f\"  üíæ Saved individual file: {safe_name}_match_logs.csv\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è  No data extracted for {player['name']}\")\n",
    "                failed_players += 1\n",
    "            \n",
    "            # Random delay between requests (0.8 to 2.0 seconds)\n",
    "            sleep_time = random.uniform(0.8, 2.0)\n",
    "            print(f\"  ‚è±Ô∏è  Sleeping for {sleep_time:.2f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error processing {player['name']}: {str(e)}\")\n",
    "            print(f\"  ‚ùå Error processing {player['name']}: {str(e)}\")\n",
    "            failed_players += 1\n",
    "            continue\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n*** SCRIPT INTERRUPTED BY USER (Ctrl+C)! ***\")\n",
    "    logging.info(\"Script interrupted by user.\")\n",
    "    raise SigTermException(\"User interrupted scraping.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Critical error in main loop: {str(e)}\")\n",
    "    print(f\"\\n‚ùå CRITICAL SCRIPT ERROR: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    # Consolidation and cleanup\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL CONSOLIDATION & CLEANUP\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nüìä Scraping Summary:\")\n",
    "        print(f\"   Successful: {successful_players}\")\n",
    "        print(f\"   Failed: {failed_players}\")\n",
    "        print(f\"   Total attempted: {successful_players + failed_players}\")\n",
    "        \n",
    "        consolidate_data(all_data_frames, OUTPUT_DIR)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during final consolidation: {str(e)}\")\n",
    "        logging.error(f\"Error during final consolidation: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nüîí Closing browser...\")\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"\\n‚úÖ Script execution completed!\")\n",
    "    print(f\"üìÅ All output saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.14 (Practice)",
   "language": "python",
   "name": "python_practice"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
