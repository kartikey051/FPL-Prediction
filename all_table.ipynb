{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb737e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Scraping 2015-2016 season...\n",
      "Saved 2015-2016 → fbref_premier_league_data/2015-2016_PremierLeague.csv\n",
      "\n",
      " Scraping 2016-2017 season...\n",
      "Saved 2016-2017 → fbref_premier_league_data/2016-2017_PremierLeague.csv\n",
      "\n",
      " Scraping 2017-2018 season...\n",
      "Saved 2017-2018 → fbref_premier_league_data/2017-2018_PremierLeague.csv\n",
      "\n",
      " Scraping 2018-2019 season...\n",
      "Saved 2018-2019 → fbref_premier_league_data/2018-2019_PremierLeague.csv\n",
      "\n",
      " Scraping 2019-2020 season...\n",
      "Saved 2019-2020 → fbref_premier_league_data/2019-2020_PremierLeague.csv\n",
      "\n",
      " Scraping 2020-2021 season...\n",
      "Saved 2020-2021 → fbref_premier_league_data/2020-2021_PremierLeague.csv\n",
      "\n",
      " Scraping 2021-2022 season...\n",
      "Saved 2021-2022 → fbref_premier_league_data/2021-2022_PremierLeague.csv\n",
      "\n",
      " Scraping 2022-2023 season...\n",
      "Saved 2022-2023 → fbref_premier_league_data/2022-2023_PremierLeague.csv\n",
      "\n",
      " Scraping 2023-2024 season...\n",
      "Saved 2023-2024 → fbref_premier_league_data/2023-2024_PremierLeague.csv\n",
      "\n",
      " Scraping 2024-2025 season...\n",
      "Saved 2024-2025 → fbref_premier_league_data/2024-2025_PremierLeague.csv\n",
      "\n",
      "All seasons scraped successfully!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time, os, re\n",
    "\n",
    " \n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2024\n",
    "\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# CHROME_DRIVER_PATH = \"C://chromedriver-win64//chromedriver.exe\" \n",
    "# service = Service(CHROME_DRIVER_PATH)\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "\n",
    "os.makedirs(\"fbref_premier_league_data\", exist_ok=True)\n",
    "\n",
    "def get_table_id(soup):\n",
    "    \n",
    "    pattern = re.compile(r\"results\\d{4}-\\d{6}_overall\")\n",
    "    match = pattern.search(soup)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\"\"\"##################################################\"\"\"\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    next_year = year + 1\n",
    "    season = f\"{year}-{next_year}\"\n",
    "    url = f\"https://fbref.com/en/comps/9/{season}/{season}-Premier-League-Stats\"\n",
    "    print(f\"\\n Scraping {season} season...\")\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    time.sleep(3)\n",
    "    html = driver.page_source\n",
    "\n",
    "    #dynamically\n",
    "    table_id = get_table_id(html)\n",
    "    if not table_id:\n",
    "        print(f\"Could not find table ID for {season}\")\n",
    "        continue\n",
    "\n",
    "   \n",
    "    try:\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, f\"table#{table_id}\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Table did not load for {season}\")\n",
    "        continue\n",
    "\n",
    "    \"\"\"##################################################\"\"\"\n",
    "    #BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"id\": table_id})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"Table not found for {season}\")\n",
    "        continue\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    headers = [\n",
    "        \"Rk\", \"Squad\", \"MP\", \"W\", \"D\", \"L\", \"GF\", \"GA\", \"GD\", \"Pts\", \"Pts/MP\", \"xG\", \"xGA\",\n",
    "        \"xGD\", \"xGD/90\", \"Attendance\", \"Top Team Scorer\", \"Goalkeeper\", \"Notes\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    \"\"\"##################################################\"\"\"\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all([\"th\", \"td\"])\n",
    "        if not cols:\n",
    "            continue\n",
    "\n",
    "        text_data = [c.get_text(strip=True) for c in cols]\n",
    "        if not text_data or not text_data[0].isdigit():\n",
    "            continue\n",
    "\n",
    "        while len(text_data) < len(headers):\n",
    "            text_data.append(\"\")\n",
    "        data.append(text_data[:len(headers)])\n",
    "\n",
    "\n",
    "    \"\"\"##################################################\"\"\"\n",
    "    if not data:\n",
    "        print(f\"No data rows found for {season}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"##################################################\"\"\"\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    \n",
    "    filename = f\"fbref_premier_league_data/{season}_PremierLeague.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {season} → {filename}\")\n",
    "\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\nAll seasons scraped successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Setup Chrome options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "# Path to your chromedriver\n",
    "service = Service(\"/path/to/chromedriver\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Load the page\n",
    "url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for JavaScript to load content\n",
    "\n",
    "# Get page source and parse with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# Locate the player wages table (adjust selector as needed)\n",
    "table = soup.find(\"table\", {\"id\": \"player_wages\"})  # Replace with actual ID or class\n",
    "\n",
    "# Extract rows\n",
    "rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "# Parse data\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if cols:\n",
    "        player_name = cols[1].text.strip()\n",
    "        nation = cols[2].text.strip()\n",
    "        position = cols[3].text.strip()\n",
    "        squad = cols[4].text.strip()\n",
    "        age = cols[5].text.strip()\n",
    "        weekly_wage = cols[6].text.strip()\n",
    "        annual_wage = cols[7].text.strip()\n",
    "        print(f\"{player_name} ({nation}, {position}, {squad}, Age {age}) - Weekly: {weekly_wage}, Annual: {annual_wage}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
