{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828dfcd1",
   "metadata": {},
   "source": [
    "This file consists of python code to load data from the mysql database to \n",
    "pandas dataframes and perform operations to clean the data before passing it on to the feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78387a97",
   "metadata": {},
   "source": [
    "Installing Necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e857a75",
   "metadata": {},
   "source": [
    "Importing Libraries and Establishing connection with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa818f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2b75d",
   "metadata": {},
   "source": [
    "Establishing connection with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection parameters\n",
    "user = os.getenv('FPL_DB_USER')\n",
    "password = os.getenv('FPL_DB_PASSWORD')\n",
    "database = os.getenv('FPL_DB_NAME')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')\n",
    "\n",
    "# Creating connection\n",
    "#   Format: mysql+mysqlconnector://user:password@host:port/database\n",
    "connection_string = f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5983ca",
   "metadata": {},
   "source": [
    "Importing MySQL Data to Python Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs={}\n",
    "\n",
    "try:\n",
    "    inspector = inspect(engine)\n",
    "    # Get all table names from the database\n",
    "    table_names = inspector.get_table_names()\n",
    "    print(f\"Found {len(table_names)} tables in the database.\")\n",
    "    print(\"==Tables in the database:==\\n\",\n",
    "          table_names,\n",
    "          \"\\n\\nStarting to import...\")\n",
    "\n",
    "    for table in table_names:\n",
    "        dfs[table] = pd.read_sql_table(table, engine)\n",
    "        print(f\"Table '{table}' imported with {len(dfs[table])} records.\")\n",
    "    \n",
    "    print(\"All tables imported with data successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred during import: {e}\")\n",
    "finally:\n",
    "    engine.dispose()\n",
    "    print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all tables in dfs\n",
    "print(\"Tables loaded into dataframes:\", list(dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c253f",
   "metadata": {},
   "source": [
    "Moving data to individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08735762",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_player_gameweeks_df = dfs['fact_player_gameweeks']\n",
    "fact_player_gameweeks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpl_fixtures_df = dfs['fpl_fixtures']\n",
    "fpl_fixtures_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d619dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpl_season_players_df = dfs['fpl_season_players']\n",
    "fpl_season_players_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpl_season_teams_df = dfs['fpl_season_teams']\n",
    "fpl_season_teams_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725018dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_history_df = dfs.get('player_history')\n",
    "player_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs.get('players')\n",
    "players_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be249b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df = dfs.get('positions')\n",
    "positions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = dfs.get('teams')\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "understat_roster_metrics_df = dfs['understat_roster_metrics']\n",
    "understat_roster_metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "understat_team_metrics_df = dfs['understat_team_metrics']\n",
    "understat_team_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f60bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"========\\nfact_player_gameweeks_df\\n\",fact_player_gameweeks_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nfpl_fixtures_df\\n\",fpl_fixtures_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nfpl_season_players_df\\n\",fpl_season_players_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nfpl_season_teams_df\\n\",fpl_season_teams_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nplayer_history_df\\n\",player_history_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nplayers_df\\n\",players_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\npositions_df\\n\",positions_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nteams_df\\n\",teams_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nunderstat_roster_metrics_df\\n\",understat_roster_metrics_df.info(),\"\\n\\n\")\n",
    "# print(\"========\\nunderstat_team_metrics_df\\n\",understat_team_metrics_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5210a",
   "metadata": {},
   "source": [
    "# Cleaning Positions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2171b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for better clarity\n",
    "positions_df = positions_df.rename(columns={\n",
    "    'id':'position_id',\n",
    "    'singular_name':'position_name',\n",
    "    'singular_name_short':'position_short_name',\n",
    "    'sqaud_select':'squad_capacity', # Total allowed in 15-man squad\n",
    "    'squad_min_play':'min_starting_size',\n",
    "    'sqaud_max_play':'max_starting_size',\n",
    "    'ui_shirt_specific':'is_gk_shirt'  # To be converted to boolean\n",
    "})\n",
    "\n",
    "# Type conversions\n",
    "positions_df['is_gk_shirt'] = positions_df['is_gk_shirt'].astype(bool)\n",
    "\n",
    "\n",
    "#sorted(positions_df.columns)\n",
    "# Reordering\n",
    "# positions_df = positions_df[[\n",
    "#     'position_id', 'position_name', 'position_short_name', \n",
    "#     'squad_capacity', 'min_starting_size', 'max_starting_size', \n",
    "#     'element_count', 'is_gk_shirt'\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6282a",
   "metadata": {},
   "source": [
    "# Cleaning fact_player_gameweeks_df\n",
    "A fact table.\n",
    "Each row in this table represents a unique event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "fact_player_gameweeks_df['value'] = fact_player_gameweeks_df['value'] / 10.0\n",
    "\n",
    "# Standardize column names across dataframes \n",
    "count_cols = [\n",
    "    'event',\n",
    "    'minutes',\n",
    "    'total_points',\n",
    "    'goals_scored', \n",
    "    'assists', \n",
    "    'clean_sheets', \n",
    "    'goals_conceded', \n",
    "    'yellow_cards', \n",
    "    'red_cards', \n",
    "    'own_goals', \n",
    "    'opponent_id'\n",
    "]\n",
    "fact_player_gameweeks_df[count_cols] = fact_player_gameweeks_df[count_cols].fillna(0).astype(int)\n",
    "\n",
    "# Sorting by time\n",
    "fact_player_gameweeks_df = fact_player_gameweeks_df.sort_values(by = ['player_id','event'])\n",
    "\n",
    "\n",
    "# Encoding location\n",
    "fact_player_gameweeks_df['is_home'] = fact_player_gameweeks_df['home_away'].apply(lambda x : 1 if x == 'H' else 0)\n",
    "\n",
    "# Resetting index\n",
    "#  After sorting the index becomes scrambled. It is reset to keep the dataframe clean\n",
    "fact_player_gameweeks_df = fact_player_gameweeks_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41a24e",
   "metadata": {},
   "source": [
    "# Cleaning fpl_fixtures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converring kickoff_time to datetime\n",
    "fpl_fixtures_df['kickoff_time'] = pd.to_datetime(fpl_fixtures_df['kickoff_time'])\n",
    "\n",
    "# Handling missing values\n",
    "#  For modeling we often fill missing scores with -1 to differentiate from a 0-0 draw\n",
    "fpl_fixtures_df['team_h_score'] = fpl_fixtures_df['team_h_score'].fillna(-1).astype(int)\n",
    "fpl_fixtures_df['team_a_score'] = fpl_fixtures_df['team_a_score'].fillna(-1).astype(int)\n",
    "\n",
    "# Extracting time features\n",
    "fpl_fixtures_df['kickoff_hour'] = fpl_fixtures_df['kickoff_time'].dt.hour\n",
    "fpl_fixtures_df['kickoff_dayofweek'] = fpl_fixtures_df['kickoff_time'].dt.day_name()\n",
    "\n",
    "# Creating a Match Result column\n",
    "# We get the match result to the model\n",
    "# H  -> Home Win, A -> Away Win, D -> Draw, U -> Unplayed\n",
    "def get_match_result(row):\n",
    "    if not row['finished']:\n",
    "        return 'U' \n",
    "    if row['team_h_score'] > row['team_a_score']:\n",
    "        return 'H' \n",
    "    elif row['team_h_score'] < row['team_a_score']:\n",
    "        return 'A' \n",
    "    else: return 'D' \n",
    "\n",
    "fpl_fixtures_df['result'] = fpl_fixtures_df.apply(get_match_result, axis=1)\n",
    "\n",
    "# Consistency check (sorting)\n",
    "fpl_fixtures_df = fpl_fixtures_df.sort_values(by=['event','kickoff_time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebaf2e",
   "metadata": {},
   "source": [
    "# Cleaning fpl_season_players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced00b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating name\n",
    "fpl_season_players_df['full_name'] = fpl_season_players_df['first_name'] + \" \" + fpl_season_players_df['second_name']\n",
    "\n",
    "# Nomralizing price\n",
    "fpl_season_players_df['now_cost'] = fpl_season_players_df['now_cost'] / 10.0\n",
    "\n",
    "# Mapping positions\n",
    "position_map = positions_df.set_index('position_id')['position_name'].to_dict()\n",
    "fpl_season_players_df['position'] = fpl_season_players_df['element_type'].map(position_map)\n",
    "\n",
    "# Extracting year\n",
    "fpl_season_players_df['season_start'] = fpl_season_players_df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# \n",
    "cols_to_keep = [\n",
    "    'season', \n",
    "    'season_start', \n",
    "    'element_id', \n",
    "    'full_name', \n",
    "    'team_id', \n",
    "    'position', \n",
    "    'total_points', \n",
    "    'now_cost'\n",
    "]\n",
    "\n",
    "fpl_season_players_df = fpl_season_players_df[cols_to_keep]\n",
    "\n",
    "# fpl_season_players_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ae6cb",
   "metadata": {},
   "source": [
    "# Cleaning fpl_season_teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44352c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming for clarity\n",
    "fpl_season_teams_df = fpl_season_teams_df.rename(columns={\n",
    "    'strength': 'fpl_difficulty_rating'\n",
    "})\n",
    "\n",
    "# Aligning Season format\n",
    "# To get numeric year\n",
    "fpl_season_teams_df['season_start'] = fpl_season_teams_df['season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Calculating Home/Away advantage\n",
    "# Some teams are stroger when they are home than away\n",
    "# Useful for a 'home_advantage_bias'. Some people perform better at their home stadium\n",
    "fpl_season_teams_df['home_advantage_bias'] = fpl_season_teams_df['strength_overall_home'] - fpl_season_teams_df['strength_overall_away']\n",
    "\n",
    "# Data type conversion\n",
    "strength_cols = [col for col in fpl_season_teams_df.columns if 'strength' in col]\n",
    "fpl_season_teams_df[strength_cols] = fpl_season_teams_df[strength_cols].astype(int)\n",
    "\n",
    "fpl_season_teams_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52fb5c",
   "metadata": {},
   "source": [
    "# Cleaning player_history_df\n",
    "This table contans information about individual match performance of every player.\n",
    "\n",
    "## Changes made\n",
    "- Renaming columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types\n",
    "# player_history_df.info()\n",
    "\n",
    "# Checking columns and values.\n",
    "\n",
    "# Find the columns with only one unique value. \n",
    "# These columns can be dropped as they do not provide any useful information.\n",
    "constant_columns = [col for col in player_history_df.columns if player_history_df[col].nunique() <= 1]\n",
    "\n",
    "# Checking ranges of data\n",
    "# To confirm if we have full\n",
    "# print(f\"Data Range: {player_history_df['kickoff_time'].min()} to {player_history_df['kickoff_time'].max()}\")\n",
    "\n",
    "\n",
    "# Dropping Irrelevant columns\n",
    "player_history_df = player_history_df.drop(columns=constant_columns)\n",
    "\n",
    "\n",
    "# Renaming columns for better clarity\n",
    "player_history_df = player_history_df.rename(columns={\n",
    "    'team_h_score':'team_home_score',\n",
    "    'team_a_score':'team_away_score',\n",
    "    'bps':'bonus_points_system_score',\n",
    "    'ict_index':'influence_creativity_threat_index'\n",
    "})\n",
    "\n",
    "\n",
    "# Type Conversion\n",
    "\n",
    "# Converting 'kickoff_time' to datetime\n",
    "player_history_df['kickoff_time'] = pd.to_datetime(player_history_df['kickoff_time'])\n",
    "\n",
    "# Boolean conversion: Columns with only two values (0 and 1) can be converted to boolean type\n",
    "# Converting `was_home`\n",
    "player_history_df['was_home'] = player_history_df['was_home'].astype(bool)\n",
    "# Converting `started`\n",
    "player_history_df['starts'] = player_history_df['starts'].astype(bool)\n",
    "\n",
    "\n",
    "# list all columns in ascending order\n",
    "sorted(player_history_df.columns)\n",
    "\n",
    "\n",
    "# Getting which team won\n",
    "\n",
    "\n",
    "def get_player_team_score(row):\n",
    "    return row['team_home_score'] if row['was_home'] else row['team_away_score']\n",
    "\n",
    "def get_opponent_team_score(row):\n",
    "    return row['team_away_score'] if row['was_home'] else row['team_home_score']\n",
    "\n",
    "# Create result column (W/D/L) based on team and opponent scores\n",
    "def get_match_result(row):\n",
    "    player_score = get_player_team_score(row)\n",
    "    opponent_score = get_opponent_team_score(row)\n",
    "\n",
    "    if player_score > opponent_score:\n",
    "        return 'W'  # Win\n",
    "    elif player_score < opponent_score:\n",
    "        return 'L'  # Loss\n",
    "    else:\n",
    "        return 'D'  # Draw\n",
    "\n",
    "player_history_df['match_result'] = player_history_df.apply(get_match_result, axis=1)\n",
    "\n",
    "# player_history_df.info()\n",
    "player_history_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96924401",
   "metadata": {},
   "source": [
    "# Cleaning player_df\n",
    "\n",
    "Contains the bio, current statues, prices and performance of each player.\n",
    "Many columns present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18733e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(players_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for better clarity\n",
    "players_df = players_df.rename(columns={\n",
    "    'now_cost': 'price',\n",
    "    'element_type': 'position_id', # This is to be mapped\n",
    "    'team': 'team_id',\n",
    "    'web_name': 'player_name'\n",
    "})\n",
    "\n",
    "# Data type conversion and normalization\n",
    "#  `price`\n",
    "players_df['price'] = players_df['price'] / 10.0  # Convert to actual price in millions\n",
    "# `selected_by_percent`\n",
    "players_df['selected_by_percent'] = players_df['selected_by_percent'].astype(float)\n",
    "\n",
    "# Mapping IDs to Descriptive Names\n",
    "#  Use mapping tables to replace numeric IDs with actual team and position names\n",
    "position_map = positions_df.set_index('position_id')['position_name'].to_dict()\n",
    "# print(position_map)\n",
    "players_df['position'] = players_df['position_id'].map(position_map)\n",
    "\n",
    "team_map = teams_df.set_index('id')['name'].to_dict()\n",
    "# print(team_map)\n",
    "players_df['team_name'] = players_df['team_id'].map(team_map)\n",
    "\n",
    "\n",
    "# Feature Selection\n",
    "#  Select only relavent columns from the player_df\n",
    "columns_to_keep = [\n",
    "    'player_name', \n",
    "    'team_name',\n",
    "    'position',\n",
    "    'price', \n",
    "    'total_points', \n",
    "    'points_per_game',\n",
    "    'form', \n",
    "    'status', \n",
    "    'chance_of_playing_next_round', \n",
    "    'selected_by_percent',\n",
    "    'minutes', \n",
    "    'goals_scored', \n",
    "    'assists', \n",
    "    'clean_sheets', \n",
    "    'bonus', \n",
    "    'bps',\n",
    "    'ict_index', 'expected_goals', \n",
    "    'expected_assists', \n",
    "    'expected_goal_involvements', \n",
    "    'expected_goals_conceded']\n",
    "\n",
    "players_df = players_df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856bbcd",
   "metadata": {},
   "source": [
    "# Cleaning teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fbf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "teams_df = teams_df.rename(columns={\n",
    "    'id':'team_id',\n",
    "    'name':'team_name',\n",
    "    'short_name':'team_short_name',\n",
    "    'strength':'overall_strength_rating'\n",
    "})\n",
    "\n",
    "# Add a full_name column by mapping the team id with a string\n",
    "team_full_name_map = {\n",
    "    1: 'Arsenal',\n",
    "    2: 'Aston Villa',\n",
    "    3: 'Bournemouth',\n",
    "    4: 'Brentford',\n",
    "    5: 'Brighton & Hove Albion',\n",
    "    6: 'Burnley',\n",
    "    7: 'Chelsea',\n",
    "    8: 'Crystal Palace',\n",
    "    9: 'Everton',\n",
    "    10: 'Fulham',\n",
    "    11: 'Leeds United',\n",
    "    12: 'Leicester City',\n",
    "    13: 'Liverpool',\n",
    "    14: 'Manchester City',\n",
    "    15: 'Manchester United',\n",
    "    16: 'Newcastle United',\n",
    "    17: 'Nottingham Forest',\n",
    "    18: 'Southampton',\n",
    "    19: 'Tottenham Hotspur',\n",
    "    20: 'West Ham United',\n",
    "    21: 'Wolverhampton Wanderers'\n",
    "}\n",
    "\n",
    "teams_df['team_full_name'] = teams_df['team_id'].map(team_full_name_map)\n",
    "\n",
    "# Selecting features\n",
    "teams_df = teams_df[[\n",
    "    'team_id', \n",
    "    'team_name', \n",
    "    'team_short_name', \n",
    "    'team_full_name',\n",
    "    'overall_strength_rating',\n",
    "    'strength_overall_home', \n",
    "    'strength_overall_away',\n",
    "    'strength_attack_home', \n",
    "    'strength_attack_away',\n",
    "    'strength_defence_home', \n",
    "    'strength_defence_away'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae172a7",
   "metadata": {},
   "source": [
    "# Cleaning understat_roster_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting match Id\n",
    "understat_roster_metrics_df['understat_match'] = understat_roster_metrics_df['match_link'].str.extract(r'(\\d+)$').astype(int) \n",
    "\n",
    "# Renaming\n",
    "understat_roster_metrics_df = understat_roster_metrics_df.rename(columns={\n",
    "    'time':'minutes_played',\n",
    "    'xg':'expected_goals',\n",
    "    'xa':'expected_assists',\n",
    "    'h_a':'location'\n",
    "})\n",
    "\n",
    "# Location encoding\n",
    "understat_roster_metrics_df['is_home'] = understat_roster_metrics_df['location'].apply(lambda x: 1 if x == 'h' else 0)\n",
    "\n",
    "# Metrics rounding\n",
    "# 2 Decimal places is standard\n",
    "adv_cols = [\n",
    "    'expected_goals', \n",
    "    'expected_assists', \n",
    "    'xgchain', \n",
    "    'xgbuildup'\n",
    "    ]\n",
    "understat_roster_metrics_df[adv_cols] = understat_roster_metrics_df[adv_cols].round(2)\n",
    "\n",
    "# Handling 'Sub' Positions\n",
    "# Understat marks players as 'Sub' if they came on. However, we often\n",
    "# want to know their ACTUAL position. We'll keep it for now but note \n",
    "# it's a \"Role\" rather than a \"Position\" in some cases.\n",
    "understat_roster_metrics_df['is_starter'] = understat_roster_metrics_df['position'].apply(lambda x: 0 if x == 'Sub' else 1)\n",
    "\n",
    "# Dropping data that is no longer needed\n",
    "understat_roster_metrics_df = understat_roster_metrics_df.drop(columns=['match_link','id','location'])\n",
    "\n",
    "understat_roster_metrics_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f40a2",
   "metadata": {},
   "source": [
    "# Cleaning understat_team_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d05635",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl_teams_df = dfs['fpl_season_teams']\n",
    "fpl_team_list = sorted(fpl_teams_df['team_name'].unique())\n",
    "\n",
    "fpl_team_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a42521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load files\n",
    "fpl_teams = dfs['fpl_season_teams']\n",
    "cs_teams = dfs['teams']\n",
    "\n",
    "fpl_teams = fpl_teams[['team_id', 'team_name', 'short_name']].drop_duplicates()\n",
    "\n",
    "cs_teams = cs_teams[['id','name','short_name']].drop_duplicates()\n",
    "cs_teams = cs_teams.rename(columns={\n",
    "    'id':'team_id',\n",
    "    'name':'team_name'\n",
    "})\n",
    "\n",
    "\n",
    "primary_ids = cs_teams['team_id'].unique()\n",
    "additional_teams = fpl_teams[~fpl_teams['team_id'].isin(primary_ids)]\n",
    "name_map = pd.concat([cs_teams, additional_teams], ignore_index=True)\n",
    "\n",
    "\n",
    "print(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize your existing name_map\n",
    "fpl_teams = dfs['fpl_season_teams'][['team_id', 'team_name', 'short_name']].drop_duplicates()\n",
    "cs_teams = dfs['teams'][['id','name','short_name']].drop_duplicates().rename(columns={'id':'team_id','name':'team_name'})\n",
    "\n",
    "primary_ids = cs_teams['team_id'].unique()\n",
    "additional_teams = fpl_teams[~fpl_teams['team_id'].isin(primary_ids)]\n",
    "name_map = pd.concat([cs_teams, additional_teams], ignore_index=True)\n",
    "\n",
    "# Understat Team Metrics Dataframe\n",
    "understat_team_metrics_df = dfs['understat_team_metrics']\n",
    "\n",
    "# Create a dictionary to fix Understat name discrepancies\n",
    "# This ensures \"Manchester City\" matches \"Man City\" in your name_map\n",
    "name_corrections = {\n",
    "    'Manchester City': 'Man City',\n",
    "    'Manchester United': 'Man Utd',\n",
    "    'Tottenham': 'Spurs',\n",
    "    'Wolverhampton Wanderers': 'Wolves',\n",
    "    'Nottingham Forest': \"Nott'm Forest\",\n",
    "    'Newcastle United': 'Newcastle',\n",
    "    'Sheffield United': 'Sheffield Utd',\n",
    "    'West Bromwich Albion': 'West Brom'\n",
    "}\n",
    "\n",
    "understat_team_metrics_df['team_h_clean'] = understat_team_metrics_df['team_h'].replace(name_corrections)\n",
    "understat_team_metrics_df['team_a_clean'] = understat_team_metrics_df['team_a'].replace(name_corrections)\n",
    "\n",
    "# Map the Unique Team IDs to the metrics table\n",
    "# Join for Home Team\n",
    "understat_team_metrics_df = understat_team_metrics_df.merge(name_map[['team_id', 'team_name']], left_on='team_h_clean', right_on='team_name', how='left')\n",
    "understat_team_metrics_df = understat_team_metrics_df.rename(columns={'team_id': 'team_h_id'}).drop(columns=['team_name'])\n",
    "\n",
    "# Join for Away Team\n",
    "understat_team_metrics_df = understat_team_metrics_df.merge(name_map[['team_id', 'team_name']], left_on='team_a_clean', right_on='team_name', how='left')\n",
    "understat_team_metrics_df = understat_team_metrics_df.rename(columns={'team_id': 'team_a_id'}).drop(columns=['team_name'])\n",
    "\n",
    "# Final Cleaning: Drop helper columns and Understat's original inconsistent IDs\n",
    "understat_team_metrics_df['date'] = pd.to_datetime(understat_team_metrics_df['date'])\n",
    "understat_team_metrics_df = understat_team_metrics_df.drop(columns=['h', 'a', 'team_h_clean', 'team_a_clean'])\n",
    "\n",
    "# Sort by date for chronological analysis\n",
    "understat_team_metrics_df = understat_team_metrics_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "understat_team_metrics_df[['date', 'team_h_id', 'team_h', 'team_a_id', 'team_a', 'h_xg', 'a_xg']].head()\n",
    "understat_team_metrics_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "cleaned_dfs = {\n",
    "    \"fact_player_gameweeks\": fact_player_gameweeks_df,\n",
    "    \"fpl_fixtures\": fpl_fixtures_df,\n",
    "    \"fpl_season_players\": fpl_season_players_df,\n",
    "    \"fpl_season_teams\": fpl_season_teams_df,\n",
    "    \"player_history\": player_history_df,\n",
    "    \"players\": players_df,\n",
    "    \"positions\": positions_df,\n",
    "    \"teams\": teams_df,\n",
    "    \"understat_roster_metrics\": understat_roster_metrics_df,\n",
    "    \"understat_team_metrics\": understat_team_metrics_df\n",
    "}\n",
    "\n",
    "%store cleaned_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e90e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Loop through and save each one\n",
    "# for name, df in cleaned_dfs.items():\n",
    "#     filename = f\"cleaned_{name}.csv\"\n",
    "#     df.to_csv(filename, index=False)\n",
    "#     print(f\"Saved: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
