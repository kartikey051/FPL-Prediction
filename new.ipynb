{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331d85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Collecting lxml\n",
      "  Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Using cached trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi>=2025.10.5 (from selenium)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.3.0)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.10)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Using cached wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from webdriver-manager) (2.32.5)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dbda.studentsdc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->webdriver-manager) (3.4.3)\n",
      "Using cached selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
      "Using cached trio-0.32.0-py3-none-any.whl (512 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, python-dotenv, pysocks, outcome, lxml, certifi, trio, webdriver-manager, trio-websocket, selenium\n",
      "\n",
      "   --- ------------------------------------  1/11 [wsproto]\n",
      "   --- ------------------------------------  1/11 [wsproto]\n",
      "   ------- --------------------------------  2/11 [python-dotenv]\n",
      "   ---------- -----------------------------  3/11 [pysocks]\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "  Attempting uninstall: certifi\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "    Found existing installation: certifi 2025.8.3\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "    Uninstalling certifi-2025.8.3:\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "      Successfully uninstalled certifi-2025.8.3\n",
      "   ------------------ ---------------------  5/11 [lxml]\n",
      "   --------------------- ------------------  6/11 [certifi]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ------------------------- --------------  7/11 [trio]\n",
      "   ----------------------------- ----------  8/11 [webdriver-manager]\n",
      "   ----------------------------- ----------  8/11 [webdriver-manager]\n",
      "   -------------------------------- -------  9/11 [trio-websocket]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ------------------------------------ --- 10/11 [selenium]\n",
      "   ---------------------------------------- 11/11 [selenium]\n",
      "\n",
      "Successfully installed certifi-2025.11.12 lxml-6.0.2 outcome-1.3.0.post0 pysocks-1.7.1 python-dotenv-1.2.1 selenium-4.38.0 sortedcontainers-2.4.0 trio-0.32.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager beautifulsoup4 pandas lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17cdc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: fbref_premier_league_data_insider01\\2015-2016\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/822bd0ba/2015-2016/Liverpool-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Liverpool_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/18bb7c10/2015-2016/Arsenal-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Arsenal_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/b8fd03ef/2015-2016/Manchester-City-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Manchester-City_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/cff3d9bb/2015-2016/Chelsea-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Chelsea_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/b2b47a98/2015-2016/Newcastle-Utd-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Newcastle-Utd_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/8602292d/2015-2016/Aston-Villa-Stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Temp\\ipykernel_14132\\1221908886.py:119: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fbref_premier_league_data_insider01\\2015-2016\\Aston-Villa_PremierLeague.csv\n",
      "Scraping (Attempt 1): https://fbref.com/en/squads/e4a775cb/2015-2016/Nott'ham-Forest-Stats\n",
      "Table not found for Nott'ham-Forest in 2015-2016. Skipping...\n",
      "Closing browser...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    153\u001b[39m             url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://fbref.com/en/squads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msquad_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-Stats\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m             scrape_team(driver, url, team, season, season_dir)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m             \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Delay to avoid rate limiting\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClosing browser...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='scraper_errors.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Create base output directory\n",
    "output_dir = \"fbref_premier_league_data_insider01\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# ADDED TO AUTOMATE DRIVER INSTALLATION AND SETUP\n",
    "# TEST IF IT WORKS FINE ON YOUR MACHINE\n",
    "# IF NOT PLEASE REVERT TO MANUAL SETUP AS COMMENTED BELOW\n",
    "# IF THIS WORKS, MAKE SURE TO INSTALL THE 'webdriver-manager' PACKAGE VIA PIP\n",
    "# pip install webdriver-manager\n",
    "# OR JUST RUN PIP INSTALL REQUREMENTS.TXT\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "\n",
    "# Initialize WebDriver (headless mode disabled for debugging)\n",
    "# ser = Service(r\"C:\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "# driver = webdriver.Chrome(service=ser)\n",
    "\n",
    "# Define seasons and teams (filtered for 2015-2016 Premier League teams)\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2024\n",
    "\n",
    "# Full team list for later seasons\n",
    "teams_full = [\n",
    "    \"Liverpool\", \"Arsenal\", \"Manchester-City\", \"Chelsea\", \"Newcastle-Utd\",\n",
    "    \"Aston-Villa\", \"Nott'ham-Forest\", \"Brighton\", \"Bournemouth\", \"Brentford\",\n",
    "    \"Fulham\", \"Crystal-Palace\", \"Everton\", \"West-Ham\", \"Manchester-Utd\",\n",
    "    \"Wolves\", \"Tottenham\", \"Leicester-City\", \"Ipswich-Town\", \"Southampton\",\"Middlesbrough\",\"Hull-City\",\"Burnley\",\"Swansea-City\",\"Stoke-City\",\"West-Bromwich-Albion\",\n",
    "    \"Huddersfield-Town\",\"Norwich-City\",\"Sheffield-United\",\"Cardiff-City\",\"Leeds-United\",\"Luton-Town\",\"Watford\",\"Sunderland\",\"Leicester\"]\n",
    "\n",
    "# Squad IDs\n",
    "squad_ids = {\n",
    "    \"Liverpool\": \"822bd0ba\",\n",
    "    \"Arsenal\": \"18bb7c10\",\n",
    "    \"Manchester-City\": \"b8fd03ef\",\n",
    "    \"Chelsea\": \"cff3d9bb\",\n",
    "    \"Newcastle-Utd\": \"b2b47a98\",\n",
    "    \"Aston-Villa\": \"8602292d\",\n",
    "    \"Nott'ham-Forest\": \"e4a775cb\",\n",
    "    \"Brighton\": \"d07537b9\",\n",
    "    \"Bournemouth\": \"4ba7cbea\",\n",
    "    \"Brentford\": \"cd051869\",\n",
    "    \"Fulham\": \"fd962109\",\n",
    "    \"Crystal-Palace\": \"47c64c55\",\n",
    "    \"Everton\": \"d3fd31cc\",\n",
    "    \"West-Ham\": \"7c21e445\",\n",
    "    \"Manchester-Utd\": \"19538871\",\n",
    "    \"Wolves\": \"8cec06e1\",\n",
    "    \"Tottenham\": \"361ca564\",\n",
    "    \"Leicester-City\": \"a2d435b3\",\n",
    "    \"Ipswich-Town\": \"b74092de\",\n",
    "    \"Southampton\": \"33c895d4\",\n",
    "    \"Norwich-City\": \"1c781004\",\n",
    "    \"Stoke-City\": \"17892952\",\n",
    "    \"Swansea-City\": \"fb10988f\",\n",
    "    \"Watford\": \"2abfe087\",\n",
    "    \n",
    "    \"Sunderland\": \"8ef52968\",\n",
    "    \"Leicester\": \"a2fb4471\",\n",
    "    \"Middlesbrough\":\"7f59c601\",\n",
    "    \"Hull-City\":\"bd8769d1\",\n",
    "    \"Burnley\":\"943e8050\",\n",
    "    \"West-Bromwich-Albion\":\"60c6b05f\",\n",
    "    \"Huddersfield-Town\":\"f5922ca5\",\n",
    "    \"Sheffield-United\":\"1df6b87e\",\n",
    "    \"Cardiff-City\":\"75fae011\",\n",
    "    \"Leeds-United\":\"5bfb9659\",\n",
    "    \n",
    "    \"Luton-Town\":\"e297cd13\",\n",
    "\n",
    "}\n",
    "\n",
    "def scrape_team(driver, url, team, season, season_dir, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Scraping (Attempt {attempt + 1}): {url}\")\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for any table with 'stats_standard' in the ID\n",
    "            WebDriverWait(driver, 60).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//table[contains(@id, 'stats_standard')]\"))\n",
    "            )\n",
    "            \n",
    "            # Parse page source\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # Find the table (try multiple possible IDs)\n",
    "            table = None\n",
    "            for table_id in [\"stats_standard_9\", \"stats_standard\", \"stats_standard_12\"]:\n",
    "                table = soup.find(\"table\", {\"id\": table_id})\n",
    "                if table:\n",
    "                    break\n",
    "            \n",
    "            if table is None:\n",
    "                logging.error(f\"Table not found for {team} in {season}\")\n",
    "                print(f\"Table not found for {team} in {season}. Skipping...\")\n",
    "                return False\n",
    "            \n",
    "            # Convert to DataFrame and save\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            filename = os.path.join(season_dir, f\"{team}_PremierLeague.csv\")\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Saved: {filename}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping {team} for {season} (Attempt {attempt + 1}): {str(e)}\")\n",
    "            print(f\"Error scraping {team} for {season} (Attempt {attempt + 1}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # Wait before retrying\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "try:\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        next_year = year + 1\n",
    "        season = f\"{year}-{next_year}\"\n",
    "        \n",
    "        # Create season subdirectory\n",
    "        season_dir = os.path.join(output_dir, season)\n",
    "        if not os.path.exists(season_dir):\n",
    "            os.makedirs(season_dir)\n",
    "            print(f\"Created directory: {season_dir}\")\n",
    "        \n",
    " \n",
    "        \n",
    "        for team in teams_full:\n",
    "            squad_id = squad_ids.get(team)\n",
    "            if not squad_id:\n",
    "                print(f\"No squad ID for {team}. Skipping...\")\n",
    "                logging.error(f\"No squad ID for {team} in {season}\")\n",
    "                continue\n",
    "                \n",
    "            url = f\"https://fbref.com/en/squads/{squad_id}/{season}/{team}-Stats\"\n",
    "            scrape_team(driver, url, team, season, season_dir)\n",
    "            time.sleep(2)  # Delay to avoid rate limiting\n",
    "\n",
    "finally:\n",
    "    print(\"Closing browser...\")\n",
    "    time.sleep(2)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f95bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
